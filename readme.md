# AICI Challenge – Object Detection & Footprint Projection into Occupancy Grid Maps  
**Author:** Rishav Sharma
**Challenge:** Projecting Object Detections into Occupancy Grid Maps (Challenge 1)
**Environment:** Office and Bathroom Surveys (MESA robot – Camera + LiDAR + TF)

---

## Overview

This repository contains a complete implementation of Challenge 1 from the AICI Computer Vision & Software Developer Coding Challenge.

The pipeline performs:

- Extraction of synchronized RGB images, LiDAR point clouds, camera intrinsics, and TF transforms from ROS2 bags  
- Object detection using YOLOv8
- LiDAR–image fusion via TF transforms
- Estimation of 3D object footprints in the camera frame
- Projection of footprints into the occupancy grid map
- Drawing oriented bounding boxes on the map 
- Exporting all outputs (PNG and JSON) into the `results/` folder

The implementation handles camera–LiDAR calibration via TF, PCA-based footprint estimation, and map projection.

---

# Repository Structure

```

aici_challenge/
│
├── data/
│   ├── office/
│   │     room.pgm
│   │     room.yaml
│   │     rosbag/
│   │     office_rgb_sample.png
│   │     office_cloud_sample.npy
│   │     office_cam_K.npy
│   │
│   └── bathroom/
│         room.pgm
│         room.yaml
│         rosbag/
│         bathroom_rgb_sample.png
│         bathroom_cloud_sample.npy
│         bathroom_cam_K.npy
│
├── results/                # Outputs generated by the pipeline
│
├── src/
│   └── aici/
│       ├── detection.py
│       ├── extract_office_samples.py
│       ├── extract_bathroom_samples.py
│       ├── office_fit_boxes.py
│       ├── bathroom_fit_boxes.py
│       ├── office_draw_map_from_cam.py
│       ├── bathroom_draw_map_from_cam.py
│       ├── project_lidar_office_tf.py
│       ├── maps.py
│       ├── tf_utils.py
│       └── test_draw_map.py
│
├── Dockerfile
├── docker-compose.yml
└── README.md

```

---

# Pipeline Summary

## 1. Extract synchronized samples (RGB + LiDAR + CameraInfo + TF)

Scripts:
```

src/aici/extract_office_samples.py
src/aici/extract_bathroom_samples.py

```

Outputs:
- `*_rgb_sample.png`  
- `*_cloud_sample.npy`  
- `*_cam_K.npy`

---

## 2. Detect objects using YOLOv8

Script:
```

src/aici/detection.py

```

Outputs:
- `*_rgb_detections.png`
- `*_detections_2d.json`
- `*_detections_2d_raw.json`

---

## 3. Fit 3D footprints using LiDAR

Scripts:
```

src/aici/office_fit_boxes.py
src/aici/bathroom_fit_boxes.py

```

Steps:
- Project LiDAR into RGB frame  
- Select all points inside each YOLO 2D bounding box  
- Depth-filter using median z  
- Fit an oriented rectangle using PCA  
- Save footprint geometry

Output:
- `*_object_footprints_cam.json`

---

## 4. Draw footprints on occupancy grid map

Scripts:
```

src/aici/office_draw_map_from_cam.py
src/aici/bathroom_draw_map_from_cam.py

```

Output:
- `*_map_detections.png`

---

# Running With Docker (Recommended)

Place rosbags in:

```

data/office/rosbag/
data/bathroom/rosbag/

```

Example:

```

data/office/rosbag/rosbag2_...*0.db3
...
data/bathroom/rosbag/rosbag2*..._0.db3

````

Build:

```bash
docker compose build
````

Run:

```bash
docker compose up
```

All outputs will appear in:

```
results/
```

---

# Running Without Docker (Local Execution)

## Requirements

| Dependency                            | Version    |
| ------------------------------------- | ---------- |
| Python                                | 3.10       |
| ROS 2                                 | Humble     |
| ultralytics                           | ≥ 8.3      |
| OpenCV                                | 4.x        |
| NumPy                                 | ≥ 1.23     |
| TFMessage, rosbag2_py, sensor_msgs_py | ROS Humble |

Install Python packages:

```bash
pip install ultralytics opencv-python numpy matplotlib
```

Source ROS2 Humble:

```bash
source /opt/ros/humble/setup.bash
```

Set PYTHONPATH:

```bash
cd aici_challenge
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
```

---

# Manual Execution

## Office Pipeline

1. Extract sample

```bash
python3 -m aici.extract_office_samples
```

2. Detect objects

```bash
python3 -m aici.detection
```

3. Fit footprints

```bash
python3 -m aici.office_fit_boxes
```

4. Draw occupancy grid overlay

```bash
python3 -m aici.office_draw_map_from_cam
```

---

## Bathroom Pipeline

1. Extract sample

```bash
python3 -m aici.extract_bathroom_samples
```

2. Detect

```bash
python3 -m aici.bathroom_detection
```

3. Fit footprints

```bash
python3 -m aici.bathroom_fit_boxes
```

4. Draw occupancy map

```bash
python3 -m aici.bathroom_draw_map_from_cam
```

---

# Notes and Limitations

* Footprints may overlap slightly due to independent PCA fitting and cluttered environments.
* Occupancy maps encode geometry, while YOLO detects semantic objects; perfect alignment is not guaranteed.
* Rosbags are not included due to size; users must place them under `data/*/rosbag/`.

---

# Final Outputs

Each survey (office and bathroom) produces:

| File                           | Description                                         |
| ------------------------------ | --------------------------------------------------- |
| `*_rgb_detections.png`         | 2D YOLO detections                                  |
| `*_detections_2d.json`         | Filtered classes (chair, couch, table, wc, bathtub) |
| `*_object_footprints_cam.json` | 3D footprint geometry                               |
| `*_map_detections.png`         | Final oriented boxes on occupancy grid              |

These outputs satisfy the Challenge 1 submission requirements.

---

# Summary

This repository provides:

* TF-based camera–LiDAR calibration
* YOLOv8-based 2D detection
* LiDAR projection into image frame
* PCA-based 3D footprint estimation
* Occupancy grid map projection
* Reproducible environment via Docker
* Clean modular Python code under `src/aici/`

To run everything in one command:

```bash
docker compose up
```

All results will appear under:

```
results/
```

```

